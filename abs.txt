For a complicated algorithm, its implementation by a human programmer usually starts with outlining a rough control flow followed by iterative en- richments, eventually yielding carefully generated syntactic structures and variables in a hierarchy. However, state-of-the-art large language models generate codes in a single pass, without interme- diate warm-ups to reflect the structured thought process of “outline-then-detail”. Inspired by the recent success of chain-of-thought prompting, we propose ChainCoder, a program synthesis lan- guage model that generates Python code progres- sively, i.e. from coarse to fine in multiple passes. We first decompose source code into layout frame components and accessory components via ab- stract syntax tree parsing to construct a hierarchical representation. We then reform our prediction target into a multi-pass objective, each pass gener- ates a subsequence, which is concatenated in the hierarchy. Finally, a tailored transformer archi- tecture is leveraged to jointly encode the natural language descriptions and syntactically aligned I/O data samples. Extensive evaluations show that ChainCoder outperforms state-of-the-arts, demonstrating that our progressive generation eases the reasoning procedure and guides the lan- guage model to generate higher-quality solutions.